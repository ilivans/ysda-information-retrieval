Learning spatiotemporal trajectories from manifold-valued longitudinal data
Jean-Baptiste Schiratti2,1, Stephanie Allassonniere2, Olivier Colliot1, Stanley Durrleman1 1 ARAMIS Lab, INRIA Paris, Inserm U1127, CNRS UMR 7225, Sorbonne Universites, UPMC Univ Paris 06 UMR S 1127, Institut du Cerveau et de la Moelle epiniere, ICM, F-75013, Paris, France 2CMAP, Ecole Polytechnique, Palaiseau, France jean-baptiste.schiratti@cmap.polytechnique.fr, stephanie.allassonniere@polytechnique.edu, olivier.colliot@upmc.fr,stanley.durrleman@inria.fr
Abstract
We propose a Bayesian mixed-effects model to learn typical scenarios of changes from longitudinal manifold-valued data, namely repeated measurements of the same objects or individuals at several points in time. The model allows to estimate a group-average trajectory in the space of measurements. Random variations of this trajectory result from spatiotemporal transformations, which allow changes in the direction of the trajectory and in the pace at which trajectories are followed. The use of the tools of Riemannian geometry allows to derive a generic algorithm for any kind of data with smooth constraints, which lie therefore on a Riemannian manifold. Stochastic approximations of the Expectation-Maximization algorithm is used to estimate the model parameters in this highly non-linear setting. The method is used to estimate a data-driven model of the progressive impairments of cognitive functions during the onset of Alzheimer's disease. Experimental results show that the model correctly put into correspondence the age at which each individual was diagnosed with the disease, thus validating the fact that it effectively estimated a normative scenario of disease progression. Random effects provide unique insights into the variations in the ordering and timing of the succession of cognitive impairments across different individuals.
1 Introduction
Age-related brain diseases, such as Parkinson's or Alzheimer's disease (AD) are complex diseases with multiple effects on the metabolism, structure and function of the brain. Models of disease progression showing the sequence and timing of these effects during the course of the disease remain largely hypothetical [3, 13]. Large databases have been collected recently in the hope to give experimental evidence of the patterns of disease progression based on the estimation of data-driven models. These databases are longitudinal, in the sense that they contain repeated measurements of several subjects at multiple time-points, but which do not necessarily correspond across subjects.
Learning models of disease progression from such databases raises great methodological challenges. The main difficulty lies in the fact that the age of a given individual gives no information about the stage of disease progression of this individual. The onset of clinical symptoms of AD may vary from forty and eighty years of age, and the duration of the disease from few years to decades. Moreover, the onset of the disease does not correspond with the onset of the symptoms: according to recent studies, symptoms are likely to be preceded by a silent phase of the disease, for which little is known. As a consequence, statistical models based on the regression of measurements with age are inadequate to model disease progression.
1

The set of the measurements of a given individual at a specific time-point belongs to a highdimensional space. Building a model of disease progression amounts to estimating continuous subject-specific trajectories in this space and average those trajectories among a group of individuals. Trajectories need to be registered in space, to account for the fact that individuals follow different trajectories, and in time, to account for the fact that individuals, even if they follow the same trajectory, may be at a different position on this trajectory at the same age.
The framework of mixed-effects models seems to be well suited to deal with this hierarchical problem. Mixed-effects models for longitudinal measurements were introduced in the seminal paper of Laird and Ware [15] and have been widely developed since then (see [6], [16] for instance). However, this kind of models suffers from two main drawbacks regarding our problem. These models are built on the estimation of the distribution of the measurements at a given time point. In many situations, this reference time is given by the experimental set up: date at which treatment begins, date of seeding in studies of plant growth, etc. In studies of ageing, using these models would require to register the data of each individual to a common stage of disease progression before being compared. Unfortunately, this stage is unknown and such a temporal registration is actually what we wish to estimate. Another limitation of usual mixed-effects models is that they are defined for data lying in Euclidean spaces. However, measurements with smooth constraints usually cannot be summed up or scaled, such as normalized scores of neurospychological tests, positive definite symmetric matrices, shapes encoded as images or meshes. These data are naturally modeled as points on Riemannian manifolds. Although the development of statistical models for manifold-valued data is a blooming topic, the construction of statistical models for longitudinal data on a manifold remains an open problem.
The concept of "time-warp" was introduced in [8] to allow for temporal registration of trajectories of shape changes. Nevertheless, the combination of the time-warps with the intrinsic variability of shapes across individuals is done at the expense of a simplifying approximation: the variance of shapes does not depend on time whereas it should adapt with the average scenario of shape changes. Moreover, the estimation of the parameters of the statistical model is made by minimizing a sum of squares which results from an uncontrolled likelihood approximation. In [18], time-warps are used to define a metric between curves that are invariant under time reparameterization. This invariance, by definition, prevents the estimation of correspondences across trajectories, and therefore the estimation of distribution of trajectories in the spatiotemporal domain. In [17], the authors proposed a model for longitudinal image data but the model is not built on the inference of a statistical model and does not include a time reparametrization of the estimated trajectories.
In this paper, we propose a generic statistical framework for the definition and estimation of mixedeffects models for longitudinal manifold-valued data. Using the tools of geometry allows us to derive a method that makes little assumptions about the data and problem to deal with. Modeling choices boil down to the definition of the metric on the manifold. This geometrical modeling also allows us to introduce the concept of parallel curves on a manifold, which is key to uniquely decompose differences seen in the data in a spatial and a temporal component. Because of the non-linearity of the model, the estimation of the parameters should be based on an adequate maximization of the observed likelihood. To address this issue, we propose to use a stochastic version of the ExpectationMaximization algorithm [5], namely the MCMC SAEM [2], for which theoretical results regarding the convergence have been proved in [4], [2].
Experimental results on neuropsychological tests scores and estimates of scenarios of AD progression are given in section 4.
2 Spatiotemporal mixed-effects model for manifold-valued data
2.1 Riemannian geometry setting
The observed data consists in repeated multivariate measurements of p individuals. For a given individual, the measurements are obtained at time points ti,1 < . . . < ti,ni . The j-th measurement of the i-th individual is denoted by yi,j. We assume that each observation yi,j is a point on a N -dimensional Riemannian manifold M embedded in RP (with P  N ) and equipped with a Riemannian metric gM. We denote M the covariant derivative. We assume that the manifold is geodesically complete, meaning that geodesics are defined for all time.
2

We recall that a geodesic is a curve drawn on the manifold  : R  M, which has no acceleration: M  = 0. For a point p  M and a vector v  TpM, the mapping ExpMp (v) denotes the Riemannian exponential, namely the point that is reached at time 1 by the geodesic starting at p with velocity v. The parallel transport of a vector X0  T(t0)M in the tangent space at point (t0) on a curve  is a time-indexed family of vectors X(t)  T(t)M which satisfies M(t)X(t) = 0 and X(t0) = X0. We denote P,t0,t(X0) the isometry that maps X0 to X(t).
In order to describe our model, we need to introduce the notion of "parallel curves" on the manifold:
Definition 1. Let  be a curve on M defined for all time, a time-point t0  R and a vector w  T(t0)M, w = 0. One defines the curve s  w(, s), called parallel to the curve , as:
w(, s) = ExpM(s) P,t0,s(w) , s  R.
The idea is illustrated in Fig. 1. One uses the parallel transport to move the vector w from (t0) to (s) along . At the point (s), a new point on M is obtained by taking the Riemannian exponential of P,t0,s(w). This new point is denoted by w(, s). As s varies, one describes a curve w(, *) on M, which can be understood as a "parallel" to the curve . It should be pointed out that, even if  is a geodesic, w(, *) is, in general, not a geodesic of M. In the Euclidean case (i.e. a flat manifold), the curve w(, *) is the translation of the curve : w(, s) = (s) + w.

Figure a)

Figure b)

Figure c)

Figure 1: Model description on a schematic manifold. Figure a) (left) : a non-zero vector wi is choosen in T(t0)M. Figure b) (middle) : the tangent vector wi is transported along the geodesic  and a point wi (, s) is constructed at time s by use of the Riemannian exponential. Figure c) (right) : The curve wi (, *) is the parallel resulting from the construction.
2.2 Generic spatiotemporal model for longitudinal data
Our model is built in a hierarchical manner: data points are seen as samples along individual trajectories, and these trajectories derive from a group-average trajectory. The model writes yi,j = wi (, i(ti,j)) + i,j, where we assume the group-average trajectory to be a geodesic, denoted  from now on. Individual trajectories derive from the group average by spatiotemporal transformations. They are defined as a time re-parameterization of a trajectory that is parallel to the group-average: t  wi (, i(t)). For the ith individual, wi denotes a non-zero tangent vector in T(t0)M, for some specific time point t0 that needs to be estimated, and which is orthogonal to the tangent vector  (t0) for the inner product given by the metric ( *, * (t0) = gM(t0)). The time-warp function i is defined as: i(t) = i(t - t0 - i) + t0. The parameter i is an acceleration factor which encodes whether the i-th individual is progressing faster or slower than the average, i is a time-shift which characterizes the advance or delay of the ith individual with respect to the average and wi is a space-shift which encodes the variability in the measurements across individuals at the same stage of progression.
The normal tubular neighborhood theorem ([11]) ensures that parallel shifting defines a spatiotemporal coordinate system as long as the vectors wi are choosen orthogonal and sufficently small. The orthogonality condition on the tangent vectors wi is necessary to ensure the identifiability of the model. Indeed, if a vector wi was not choosen orthogonal, its orthogonal projection would play the same role as the acceleration factor.The spatial and temporal transformations commute, in the sense that one may re-parameterize the average trajectory before building the parallel curve, or vice versa. Mathematically, this writes wi (  i, s) = wi (, i(s)). This relation also explains the particular form of the affine time-warp i. The geodesic  is characterized by the fact that it passes

3

at time-point t0 by point p0 = (t0) with velocity v0 =  (t0). Then,   i is the same trajectory, except that it passes by point p0 at time t0 + i with velocity iv0.

The fixed effects of the model are the parameters of the average geodesic: the point p0 on the manifold, the time-point t0 and the velocity v0. The random effects are the acceleration factors i, time-shifts i and space-shifts wi. The first two random effects are scalars. One assumes the
acceleration factors to follow a log-normal distribution (they need to be positive in order not to
reverse time), and time-shifts to follow a zero-mean Gaussian distribution. Space-shifts are vectors of dimension N - 1 in the hyperplane  (t0) in T(t0)M. In the spirit of independent component analysis [12], we assume that wi's result from the superposition of Ns < N statistically independent components. This writes wi = Asi where A is a N x Ns matrix of rank Ns, si a vector of Ns independent sources following a heavy tail Laplace distribution with fixed parameter, and each column cj(A) (1  j  Ns) of A satisfies the orthogonality condition cj(A),  (t0) (t0) = 0.

For the dataset (ti,j, yi,j) (1  i  p, 1  j  ni), the model may be summarized as: yi,j = wi (, i(ti,j )) + i,j .

(1)

with i(t) = i(t - t0 - i) + t0, i = exp(i), wi = Asi and
i i.i.d. N (0, 2), i i.i.d. N (0, 2), i,j i.i.d. N (0, 2IN ), si,l i.i.d. Laplace(1/2). Eventually, the parameters of the model one needs to estimate are the fixed effects and the variance of the random effects, namely  = (p0, t0, v0, ,  , , vec(A)).

2.3 Propagation model in a product manifold

We wish to use these developments to study the temporal progression of a family of biomarkers.
We assume that each component of yi,j is a scalar measurement of a given biomarker and belongs to a geodesically complete one-dimensional manifold (M, g). Therefore, each measurement yi,j is a point in the product manifold M = M N , which we assume to be equipped with the Riemannian product metric gM = g + . . . + g. We denote 0 the geodesic of the one-dimensional manifold M which goes through the point p0  M at time t0 with velocity v0  Tp0 M . In order to determine relative progression of the biomarkers among themselves, we consider a parametric family of
geodesics of M : (t) = 0(t), 0(t+1), . . . , 0(t+N-1) . We assume here that all biomarkers have on average the same dynamics but shifted in time. This hypothesis allows to model a temporal
succession of effects during the course of the disease. The relative timing in biomarker changes is
measured by the vector  = 0, 1, . . . , N-1 , which becomes a fixed effect of the model.

In this setting, a curve that is parallel to a geodesic  is given by the following lemma :

Lemma 1. Let  be a geodesic of the product manifold M = M N and let t0  R. If

w(, *) denotes a parallel to the geodesic  with w = (w1, . . . , wN  T(t0)M and (t) =

(1(t), . . . , N (t)), we have w(, s) =

1

w1  (t0)

+s

, . . . , N

wN  (t0)

+

s

, s  R.

As a consequence, a parallel to the average trajectory  has the same form as the geodesic but with randomly perturbed delays. The model (1) writes : for all k  {1, . . . , N },

yi,j,k = 0

wk,i 0(t0 + k-1)

+

i(ti,j

-

t0

-

i)

+

t0

+

k-1

+ i,j,k.

(2)

where wk,i denotes the k-th component of the space-shift wi and yi,j,k, the measurement of the k-th biomarker, at the j-th time point, for the i-th individual.

2.4 Multivariate logistic curves model

The propagation model given in (2) is now described for normalized biomarkers, such as scores of

neuropsychological tests. In this case, we assume the manifold to be M =]0, 1[ and equipped with

the Riemannian metric g given by : for p ]0, 1[, (u, v)  TpM x TpM , gp(u, v) = uG(p)v with G(p) = 1/(p2(1 - p)2). The geodesics given by this metric in the one-dimensional Riemannian

manifold M are logistic curves of the form : 0(t) =

1

+

(

1 p0

-

1) exp

-

p0

v0 (1-p0

)

(t

-

t0)

-1

and leads to the multivariate logistic curves model in M. We can notice the quite unusual paramater-

ization of the logistic curve. This parametrization naturally arise because 0 satisfies : 0(t0) = p0

and 0(t0) = v0. In this case, the model (1) writes:

4

yi,j,k =

1 1 + - 1 exp
p0

-

v0i(ti,j

-

t0

-

i)

+

v0k

+

v (Asi)k
0 0(t0+k)

p0(1 - p0)

-1
+ i,j,k, (3)

where (Asi)k denotes the k-th component of the vector Asi. Note that (3) is not equivalent to a linear model on the logit of the observations. The logit transform corresponds to the Riemannian
logarithm at p0 = 0.5. In our framework, p0 is not fixed, but estimated as a parameter of our model. Even with a fixed p0 = 0.5, the model is still non-linear due to the multiplication between random-effects i and i, and therefore does not boil down to the usual linear model [15].

3 Parameters estimation

In this section, we explain how to use a stochastic version of the Expectation-Maximization (EM) algorithm [5] to produce estimates of the parameters  = (p0, t0, v0, , ,  , , vec(A)) of the model. The algorithm detailed in this section is essentially the same as in [2]. Its scope of application is not limited to statistical models on product manifolds and the MCMC-SAEM algorithm can actually be used for the inference of a very large family of statistical models.

The random effects z = (i, i, sj,i) (1  i  p and 1  j  Ns) are considered as hidden variables. With the observed data y = (yi,j,k)i,j,k, (y, z) form the complete data of the model. In this context, the Expectation-Maximization (EM) algorithm proposed in [5] is very efficient to compute the maximum likelihood estimate of . Due to the nonlinearity and complexity of the model, the E step is
intractable. As a consequence, we considered a stochastic version of the EM algorithm, namely the
Monte-Carlo Markov Chain Stochastic Approximation Expectation-Maximization (MCMC-SAEM)
algorithm [2], based on [4]. This algorithm is an EM-like algorithm which alternates between three steps: simulation, stochastic approximation and maximization. If (t) denotes the current parameter estimates of the algorithm, in the simulation step, a sample z(t) of the missing data is obtained from
the transition kernel of an ergodic Markov chain whose stationary distribution is the conditional distribution of the missing data z knowing y and (t), denoted by q(z | y, (t)). This simulation
step is achieved using Hasting-Metropolis within Gibbs sampler. Note that the high complexity of
our model prevents us from resorting to sampling methods as in [10] as they would require heavy
computations, such as the Fisher information matrix. The stochastic approximation step consists in a stochastic approximation on the complete log-likelihood log q(y, z | ) summarized as follows : Qt() = Qt-1() + t [log q(y, z | ) - Qt-1()], where (t)t is a decreasing sequence of positive step-sizes in ]0, 1] which satisfies t t = + and t 2t < +. Finally, the parameter estimates are updated in the maximization step according to: (t+1) = argmax Qt().

The theoretical convergence of the MCMC SAEM algorithm is proved only if the model be-

long to the curved exponential family. Or equivalently, if the complete log-likelihood of the

model may be written : log q(y, z | ) = -() + S(y, z) (), where S(y, z) is a sufficent

statistic of the model. In this case, the stochastic approximation on the complete log-likelihood

can be replaced with a stochastic approximation on the sufficent statistics of the model. Note

that the multivariate logistic curves model does not belong to the curved exponential family. A

usual workaround consists in regarding the parameters of the model as realizations of indepen-

dents Gaussian random variables ([14]) :   N (, D) where D is a diagonal matrix with

very small diagonal entries and the estimation now targets . This yields: p0  N (p0, p20 ),

t0  N (t0, t20 ), v0  N (v0, v20 ) and, for all k, k  N (k, 2). To ensure the orthogonality condition on the columns of A, we assumed that A follows a normal distribution on the

space  = {A = (c1(A), . . . , cNs (A))  T(t0)M Ns ; j, cj (A), (t0) (t0) = 0}.

Equivalently, we assume that the matrix A writes : A =

(N -1)Ns k=1

k Bk

where,

for

all

k,

k i.i.d. N (k, 2 ) and (B1, . . . , B(N-1)Ns ) is an orthonormal basis of  obtained by applica-

tion of the Gram-Schmidt process to a basis of . The random variables 1, . . . , (N-1)Ns are considered as new hidden variables of the model. The parameters of the model are  =

(p0, t0, v0, (k)1kN-1, (k)1k(N-1)Ns , ,  , ) whereas the hidden variables of the model
are z = (p0, t0, v0, (k)1kN-1, (k)1k(N-1)Ns , (i)1ip, (i)1ip, (sj,i)1jNs, 1ip). The algorithm (1) given below summarizes the SAEM algorithm for this model.

The MCMC-SAEM algorithm 1 was tested on synthetic data generated according to (3). The MCMC-SAEM allowed to recover the parameters used to generate the synthetic dataset.

5

Algorithm 1 Overview of the MCMC SAEM algorithm for the multivariate logistic curves model.

If z(k) = p(0k), t(0k), . . . , (s(jk,i) denotes the vector of hidden variables obtained in the simulation step of the k-th iteration of the MCMC SAEM, let fi,j = [fi,j,l]  RN and fi,j,l

be the l-th component of wi(k) ()(k), exp(i(k))(ti,j - t(0k) - i(k)) + t(0k)

(N -1)Ns l=1

l(k)Bl.

and wi(k) =

Initialization :

  (0) ; z(0)  random ; S  0 ; (k)k0.

repeat

Simulation step : z(k) = p(0k), t(0k), . . . , (s(jk,i))j,i  Gibbs Sampler(z(k-1), y, (k-1))

Compute the sufficent statistics : S(1k)  yi,j fi,j i,j  RK ; S(2k)  fi,j 2 i,j  RK

with (1  i  p ; 1  j  ni) and K =

p i=1

ni

;

S(3k)

=

(i(k))2 i  Rp ; S(4k) 

(i(k))2 i  Rp ; S(5k)  p(0k) ; S(6k)  t(0k) ; S(7k)  v0(k) ; S(8k)  j(k) j  RN-1 ;

S(9k)  j(k) j  R(N-1)Ns .

Stochastic approximation step : S(jk+1)  S(jk) + k(S(y, z(k)) - S(jk)) for j  {1, . . . , 9}.

Maximization step : p0(k+1)  S(5k) ; t0(k+1)  S(6k) ; v0(k+1)  S(7k) ; (jk+1)  (S(8k))j

for

all

1



j



N

-1

;



(k+1) j



(S(9k))j

for

all

1



j



(N

- 1)Ns

;

(k+1)



1 p

(S(3k)

)

1p

; (k+1)



1 p

(S(4k))

1p

;

(k+1)



1 NK

until convergence.

i,j,k yi2,j,k - 2(S(1k)) 1K + (S(2k)) 1K 1/2.

return .

4 Experiments
4.1 Data
We use the neuropsychological assessment test "ADAS-Cog 13" from the ADNI1, ADNIGO or ADNI2 cohorts of the Alzheimer's Disease Neuroimaging Initiative (ADNI) [1]. The "ADAS-Cog 13" consists of 13 questions, which allow to test the impairment of several cognitive functions. For the purpose of our analysis, these items are grouped into four categories: memory (5 items), language (5 items), praxis (2 items) and concentration (1 item). Scores within each category are added and normalized by the maximum possible score. Consequently, each data point consists in four normalized scores, which can be seen as a point on the manifold M =]0, 1[4.
We included 248 individuals in the study, who were diagnosed with mild cognitive impairment (MCI) at their first visit and whose diagnosis changed to AD before their last visit. There is an average of 6 visits per subjects (min: 3, max: 11), with an average duration of 6 or 12 months between consecutive visits. The multivariate logistic curves model was used to analyze this longitudinal data.
4.2 Experimental results
The model was applied with Ns = 1, 2 or 3 independent sources. In each experiment, the MCMC SAEM was run five times with different initial parameter values. The experiment which returned the smallest residual variance 2 was kept. The maximum number of iterations was arbitrarily set to 5000 and the number of burn-in iterations was set to 3000 iterations. The limit of 5000 iterations is enough to observe the convergence of the sequences of parameters estimates. As a result, two and three sources allowed to decrease the residual variance better than one source (2 = 0.012 for one source, 2 = 0.08 for two sources and 2 = 0.084 for three sources). The residual variance 2 = 0.012 (resp. 2 = 0.08, 2 = 0.084) mean that the model allowed to explain 79% (resp. 84%, 85%) of the total variance. We implemented our algorithm in MATLAB without any particular optimization scheme. The 5000 iterations require approximately one day.
The number of parameters to be estimated is equal to 9 + 3Ns. Therefore, the number of sources do not dramatically impact the runtime. Simulation is the most computationally expensive part of
6

our algorithm. For each run of the Hasting-Metropolis algorithm, the proposal distribution is the prior distribution. As a consequence, the acceptation ratio simplifies [2] and one computation of the acceptation ratio requires two computations of the likelihood of the observations, conditionally on different vectors of latent variables and the vector of current parameters estimates. The runtime could be improved by parallelizing the sampling per individuals.
For a matter of clarity and because the results obtained with three sources were similar to the results with two sources, we report here the experimental results obtained with two independent sources. The average model of disease progression  is plotted in Fig. 2. The estimated fixed effects are p0 = 0.3, t0 = 72 years, v0 = 0.04 unit per year, and  = [0; -15; -13; -5] years. This means that, on average, the memory score (first coordinate) reaches the value p0 = 0.3 at t0 = 72 years, followed by concentration which reaches the same value at t0 + 5 = 77 years, and then by praxis and language at age 85 and 87 years respectively.
Random effects show the variability of this average trajectory within the studied population. The standard deviation of the time-shift equals  = 7.5 years, meaning that the disease progression model in Fig. 2 is shifted by 7.5 years to account for the variability in the age of disease onset. The effects of the variance of the acceleration factors, and the two independent components of the space-shifts are illustrated in Fig. 4. The acceleration factors shows the variability in the pace of disease progression, which ranges between 7 times faster and 7 times slower than the average. The first independent component shows variability in the relative timing of the cognitive impairments: in one direction, memory and concentration are impaired nearly at the same time, followed by language and praxis; in the other direction, memory is followed by concentration and then language and praxis are nearly superimposed. The second independent component keeps almost fixed the timing of memory and concentration, and shows a great variability in the relative timing of praxis and language impairment. It shows that the ordering of the last two may be inverted in different individuals. Overall, these space-shift components show that the onset of cognitive impairment tends to occur by pairs: memory & concentration followed by language & praxis.
Individual estimates of the random effects are obtained from the simulation step of the last iteration of the algorithm and are plotted in Fig. 5. The figure shows that the estimated individual time-shifts correspond well to the age at which individuals were diagnosed with AD. This means that the value p0 estimated by the model is a good threshold to determine diagnosis (a fact that has occurred by chance), and more importantly that the time-warp correctly register the dynamics of the individual trajectories so that the normalized age correspond to the same stage of disease progression across individuals. This fact is corroborated by Fig. 3 which shows that the normalized age of conversion to AD is picked at 77 years old with a small variance compared to the real distribution of age of conversion.

Figure 2: The four curves represent the estimated average trajectory. A vertical line is drawn at t0 = 72 years old and an horizontal line is drawn at p0 = 0.3.

Figure 3: In blue (resp. red) : histogram of the ages of conversion to AD (tdiiag) (resp. normalized ages of conversion to AD (i(tdiiag))), with i time-warp as in (1).

7

Acceleration factor 

Independent component 1 Independent component 2

-

+
Figure 4: Variability in disease progression superimposed with the average trajectory  (dotted lines): effects of the acceleration factor with plots of  exp()(t - t0) + t0 (first column), first and second independent component of space-shift with plots of si ci(A)(, *) for i = 1 or 2 (second and third column respectively).
Figure 5: Plots of individual random effects: log-acceleration factor i = log(i) against time-shifts t0 + i. Color corresponds to the age of conversion to AD.
4.3 Discussion and perspectives
We proposed a generic spatiotemporal model to analyze longitudinal manifold-valued measurements. The fixed effects define a group-average trajectory, which is a geodesic on the data manifold. Random effects are subject-specific acceleration factor, time-shift and space-shift which provide insightful information about the variations in the direction of the individual trajectories and the relative pace at which they are followed. This model was used to estimate a normative scenario of Alzheimer's disease progression from neuropsychological tests. We validated the estimates of the spatiotemporal registration between individual trajectories by the fact that they put into correspondence the same event on individual trajectories, namely the age at diagnosis. Alternatives to estimate model of disease progression include the event-based model [9], which estimates the ordering of categorical variables. Our model may be seen as a generalization of this model for continuous variables, which do not only estimate the ordering of the events but also the relative timing between them. Practical solutions to combine spatial and temporal sources of variations in longitudinal data are given in [7]. Our goal was here to propose theoretical and algorithmic foundations for the systematic treatment of such questions.
8

References
[1] The Alzheimer's Disease Neuroimaging Initiative, https://ida.loni.usc.edu/ [2] Allassonniere, S., Kuhn, E., Trouve, A.: Construction of bayesian deformable models via a stochastic
approximation algorithm: a convergence study. Bernoulli 16(3), 641-678 (2010) [3] Braak, H., Braak, E.: Staging of alzheimer's disease-related neurofibrillary changes. Neurobiology of
aging 16(3), 271-278 (1995) [4] Delyon, B., Lavielle, M., Moulines, E.: Convergence of a stochastic approximation version of the em
algorithm. Annals of statistics pp. 94-128 (1999) [5] Dempster, A.P., Laird, N.M., Rubin, D.B.: Maximum likelihood from incomplete data via the em algo-
rithm. Journal of the royal statistical society. Series B (methodological) pp. 1-38 (1977) [6] Diggle, P., Heagerty, P., Liang, K.Y., Zeger, S.: Analysis of longitudinal data. Oxford University Press
(2002) [7] Donohue, M.C., Jacqmin-Gadda, H., Le Goff, M., Thomas, R.G., Raman, R., Gamst, A.C., Beckett, L.A.,
Jack, C.R., Weiner, M.W., Dartigues, J.F., Aisen, P.S., the Alzheimer's Disease Neuroimaging Initiative: Estimating long-term multivariate progression from short-term data. Alzheimer's & Dementia 10(5), 400- 410 (2014) [8] Durrleman, S., Pennec, X., Trouve, A., Braga, J., Gerig, G., Ayache, N.: Toward a comprehensive framework for the spatiotemporal statistical analysis of longitudinal shape data. International Journal of Computer Vision 103(1), 22-59 (2013) [9] Fonteijn, H.M., Modat, M., Clarkson, M.J., Barnes, J., Lehmann, M., Hobbs, N.Z., Scahill, R.I., Tabrizi, S.J., Ourselin, S., Fox, N.C., et al.: An event-based model for disease progression and its application in familial alzheimer's disease and huntington's disease. NeuroImage 60(3), 1880-1889 (2012) [10] Girolami, M., Calderhead, B.: Riemann manifold langevin and hamiltonian monte carlo methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 73(2), 123-214 (2011) [11] Hirsch, M.W.: Differential topology. Springer Science & Business Media (2012) [12] Hyvarinen, A., Karhunen, J., Oja, E.: Independent component analysis, vol. 46. John Wiley & Sons (2004) [13] Jack, C.R., Knopman, D.S., Jagust, W.J., Shaw, L.M., Aisen, P.S., Weiner, M.W., Petersen, R.C., Trojanowski, J.Q.: Hypothetical model of dynamic biomarkers of the alzheimer's pathological cascade. The Lancet Neurology 9(1), 119-128 (2010) [14] Kuhn, E., Lavielle, M.: Maximum likelihood estimation in nonlinear mixed effects models. Computational Statistics & Data Analysis 49(4), 1020-1038 (2005) [15] Laird, N.M., Ware, J.H.: Random-effects models for longitudinal data. Biometrics pp. 963-974 (1982) [16] Singer, J.D., Willett, J.B.: Applied longitudinal data analysis: Modeling change and event occurrence. Oxford university press (2003) [17] Singh, N., Hinkle, J., Joshi, S., Fletcher, P.T.: A hierarchical geodesic model for diffeomorphic longitudinal shape analysis. In: Information Processing in Medical Imaging. pp. 560-571. Springer (2013) [18] Su, J., Kurtek, S., Klassen, E., Srivastava, A., et al.: Statistical analysis of trajectories on riemannian manifolds: Bird migration, hurricane tracking and video surveillance. The Annals of Applied Statistics 8(1), 530-552 (2014)
9

