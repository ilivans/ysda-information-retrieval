Predtron: A Family of Online Algorithms for General Prediction Problems

Prateek Jain Microsoft Research, INDIA prajain@microsoft.com

Nagarajan Natarajan University of Texas at Austin, USA
naga86@cs.utexas.edu

Ambuj Tewari University of Michigan, Ann Arbor, USA
tewaria@umich.edu

Abstract
Modern prediction problems arising in multilabel learning and learning to rank pose unique challenges to the classical theory of supervised learning. These problems have large prediction and label spaces of a combinatorial nature and involve sophisticated loss functions. We offer a general framework to derive mistake driven online algorithms and associated loss bounds. The key ingredients in our framework are a general loss function, a general vector space representation of predictions, and a notion of margin with respect to a general norm. Our general algorithm, Predtron, yields the perceptron algorithm and its variants when instantiated on classic problems such as binary classification, multiclass classification, ordinal regression, and multilabel classification. For multilabel ranking and subset ranking, we derive novel algorithms, notions of margins, and loss bounds. A simulation study confirms the behavior predicted by our bounds and demonstrates the flexibility of the design choices in our framework.
1 Introduction
Classical supervised learning problems, such as binary and multiclass classification, share a number of characteristics. The prediction space (the space in which the learner makes predictions) is often the same as the label space (the space from which the learner receives supervision). Because directly learning discrete valued prediction functions is hard, one learns real-valued or vector-valued functions. These functions generate continuous predictions that are converted into discrete ones via simple mappings, e.g., via the `sign' function (binary classification) or the `argmax' function (multiclass classification). Also, the most commonly used loss function is simple, viz. the 0-1 loss. In contrast, modern prediction problems, such as multilabel learning, multilabel ranking, and subset ranking do not share these characteristics. In order to handle these problems, we need a more general framework that offers more flexibility. First, it should allow for the possibility of having different label space and prediction space. Second, it should allow practitioners to use creative, new ways to map continuous, vector-valued predictions to discrete ones. Third, it should permit the use of general loss functions. Extensions of the theory of classical supervised learning to modern predictions problems have begun. For example, the work on calibration dimension [1] can be viewed as extending one aspect of the theory, viz. that of calibrated surrogates and consistent algorithms based on convex optimization. This paper deals with the extension of another interesting part of classical supervised learning: mistake driven algorithms such as perceptron (resp. winnow) and their analyses in terms of 2 (resp. 1) margins [2, Section 7.3].
1

We make a number of contributions. First, we provide a general framework (Section 2) whose ingredients include an arbitrary loss function and an arbitrary representation of discrete predictions in a continuous space. The framework is abstract enough to be of general applicability but it offers enough mathematical structure so that we can derive a general online algorithm, Predtron (Algorithm 1), along with an associated loss bound (Theorem 1) under an abstract margin condition (Section 2.2). Second, we show that our framework unifies several perception-like algorithms for classical problems such as binary classification, multiclass classification, ordinal regression, and multilabel classification (Section 3). Even for these classical problems, we get some new results, for example, when the loss function treats labels asymmetrically or when there exists a `reject' option in classification. Third, we apply our framework to two modern prediction problems: subset ranking (Section 4) and multilabel ranking (Section 5). In both of these problems, the prediction space (rankings) is different from the supervision space (set of labels or vector of relevance scores). For these two problems, we propose interesting, novel notions of correct prediction with a margin and derive mistake bounds under a loss derived from NDCG, a ranking measure that pays more attention to the performance at the top of a ranked list. Fourth, our techniques based on online convex optimization (OCO) can effortlessly incorporate notions of margins w.r.t. non-Euclidean norms, such as 1 norm, group norm, and trace norm. Such flexibility is important in modern prediction problems where the learned parameter can be a high dimensional vector or a large matrix with low group or trace norm. Finally, we test our theory in a simulation study (Section 6) dealing with the subset ranking problem showing how our framework can be adapted to a specific prediction problem. We investigate different margin notions as we vary two key design choices in our abstract framework: the map used to convert continuous predictions into discrete ones, and the choice of the norm used in the definition of margin. Related Work. Our general algorithm is related to the perceptron and online gradient descent algorithms used in structured prediction [3, 4]. But, to the best of knowledge, our emphasis on keeping label and prediction spaces possibly distinct, our use of a general representation of predictions, and our investigation of generalized notions of margins are all novel. The use of simplex coding in multiclass problems [5] inspired the use of maximum similarity/minimum distance decoding to obtain discrete predictions from continuous ones. Our proofs use results about Online Gradient Descent and Online Mirror Descent from the Online Convex Optimization literature [6].
2 Framework and Main Result
The key ingredients in classic supervised learning are an input space, an output space and a loss function. In this paper, the input space X 2 Rp will always be some subset of a finite dimensional Euclidean space. Our algorithms maintain prediction functions as a linear combination of the seen inputs. As a result, they easily kernelize and the theory extends, in a straightforward way to the case when the input space is a, possibly infinite dimensional, reproducing kernel Hilbert space (RKHS). 2.1 Labels, Prediction, and Scores We will distinguish between the label space and the prediction space. The former is the space where the training labels come from whereas the latter is the space where the learning algorithm has to make predictions in. Both spaces will be assumed to be finite. Therefore, without any loss of generality, we can identify the label space with [] = {1, . . . , } and the prediction space with [k] where , k are positive, but perhaps very large, integers. A given loss function L : [k]  [] ! R+ maps a prediction 2 [k] and a label y 2 [] to a non-negative loss L( , y). The loss L can equivalently be thought of as a k   matrix with loss values as entries. Define the set of correct predictions for a label y as y = { y 2 [k] : L( y, y) = 0}. We assume that, for every label y, the set y is non-empty. That is, every column of the loss matrix has a zero entry. Also, let ceLntr=iesminintLh(e l,oy)s>s 0mLat(rix,.y) and CL = max ,y L( , y) be the minimum (non-zero) and maximum In an online setting, the learner will see a stream of examples (X , Y ) 2 X  []. Learner will predict scores using a linear predictor W 2 Rdp. However, the predicted scores W X will be in Rd, not in the prediction space [k]. So, we need a function pred : Rd ! [k] to convert scores into actual predictions. We will assume that there is a unique representation rep( ) 2 Rd of each
2

prediction such that k rep( )k2 = 1 for all . Given this, a natural transformation of scores into prediction is given by the following maximum similarity decoding:

pred(t) 2 argmax hrep( ), ti ,
2[k]

(1)

where ties in the "argmax" can be broken arbitrarily. There are some nice consequences of the definition of pred above. First, because k rep( )k2 = 1, maximum similarity decoding is equivalent to nearest neighbor decoding: pred(t) 2 argmin k rep( ) tk2. Second, we have a homogeneity property: pred(ct) = pred(t) if c > 0. Third, rep serves as an "inverse" of pred in the following sense. We have, pred(rep( )) = for all . Moreover, rep(pred(t)) is more similar to t than the representation of any other prediction :

8t 2 Rd, 2 [k], hrep(pred(t)), ti hrep( ), ti .

In view of these facts, we will use pred 1( ) and rep( ) interchangeably. Using pred, the loss function L can be extended to a function defined on Rd  [k] as:

L(t, y) = L(pred(t), y).

With a little abuse of notation, we will continue to denote this new function also by L.

2.2 Margins

We say that a score t is compatible with a label y if the set

definition y 2 y,

(1)2/ofpyr, ewdeishaevxeactplyredy

.
1

That ( y),

is, t

argmax > pred

2[k]
1(

o)f,ptre'.sdTthh1ae(t

achieve ), t =

the y

maximum in . Hence, for

the any

notion of margin makes this

requirement stronger. We say that a score t has a margin > 0 on label y, iff t is compatible with

y and

8 y 2 y,

 2/ y, pred

1(

 y), t

 pred

1(

 ), t +

Note that margin scales with t: if t has margin on y then ct has margin c on y for any positive c.

If we are using linear predictions t = W X, we say that W has margin on (X, y) iff t = W X has

margin on y. We say that W has margin on a dataset (X1, y1), . . . , (Xn, yn) iff W has margin

on (X , y ) with margin

for all  2 [n]. Finally, a if there is a unit norm1

dataset (X1, y1), W ? such that W

. . . , (Xn, yn) ? has margin

is said to be linearly separable on (X1, y1), . . . , (Xn, yn).

2.3 Algorithm

Just like the classic perceptron algorithm, our generalized perceptron algorithm (Algorithm 1) is

mistake driven. That is, it only updates on round when a mistake, i.e., a non-zero loss, is incurred.

ORopnendr,caaXepfmrterioss2htna,kRicnepap.rnuotTbuenhXdekr,eeirisftnogemrlievia,zekeWneds.bayarlPawnakiy-gsoinhheXasuip,aXdraeitperweohsfeitcnhhteatmfiooernamnosfWtthhe+e 1afol=grmorWiPthmi g, ijgXusi>t*

.XT>hewphreerdeigctio2n like the original

We will give a loss bound for the algorithm using tools from Online Convex Optimization (OCO). Define the function : Rd  [] ! R as

(t, y) = max L( , y)

 pred

1(

y)

pred

1(

 ), t

2[k]

(2)

where y 2 y is an arbitrary member of y. For any y, (*, y) is a point-wise maximum of linear functions and hence convex. Also, is non-negative: choose = y to lower bound the maximum. The inner product part vanishes and the loss L( y, y) vanishes too because y 2 y. Given the definition of , Algorithm 1 can be described succinctly as follows. At round  , if L(W X , Y ) > 0, then W+1 = W rW (W X , Y ), otherwise W+1 = W .

1Here, we mean that the Frobenius norm kW ?kF equals 1. Of course, the notion of margin can be generalized to any norm including the entry-based 1 norm kW k1 and the spectrum-based 1 norm kW kS(1) (also called the nuclear or trace norm). See Appendix B.2.

3

Algorithm 1 Predtron: Extension of the Perceptron Algorithm to General Prediction Problems

1: 2:

Wfor1 

0 = 1, 2, . . . do

3: Receive X 2 Rp

4: Predict  = pred(W X ) 2 [k]

5: Receive label y 2 []

6: if L(  , y ) > 0 then

7: 8:

(t, y) = (W X , y )  = argmax 2[k] L( , y)

 pred

1(

y)

pred

1(

 ), t

2 [k]

9: r = (pred 1( ) pred 1( y)) * X> 2 Rdp

10: 11:

elsWe +1 = W

r

12: 13:

endWif+1 = W

14: end for

Theorem 1. Suppose the dataset (X1, y1), . . . , (Xn, yn) is linearly separable with margin the sequence W generated by Algorithm 1 with  = cL/(4R2) satisfies the loss bound,

Xn L(W X , y )
 =1



4R2CL2 cL 2

where kX k2  R for all  .

. Then

Note that the bound above assumes perfect linear separability. However, just the classic perceptron, the bound will degrade gracefully when the best linear predictor does not have enough margin on the data set.

The Predtron algorithm has some interesting variants, two of which we consider in the appendix. A loss driven version, Predtron.LD, enjoys a loss bound that gets rid of the CL/cL factor in the bound above. A version, Predtron.Link, that uses link functions to deal with margins defined with respect to non-Euclidean norms is also considered.

3 Relationship to Existing Results

It is useful to discuss a few concrete applications of the abstract framework introduced in the last section. Several existing loss bounds can be readily derived by applying our bound for the generalized perceptron algorithm in Theorem 1. In some cases, our framework yields a different algorithm than existing counterparts, yet admitting identical loss bounds, up to constants.

Binary Classification. We begin with the classical perceptron algorithm for binary classification

(i.e.,  = 2) [7]: L0-1( , y) = 1 if 6= y or 0 otherwise. Letting rep( ) be +1 for the positive class and 1 for the negative class, predictor vector W 2 R1p, and thus pred(t) = sign(t), Algorithm 1 reduces to the original perceptron algorithm; Theorem 1 yields identical mistake bound

on a 2 ),

il.ien.eaPrlyn=se1pLa0r-a1b(lWe dXatas,eyt

with )

margin

R2
2

.

We

(if can

the classical margin is also easily incorporate

, ours works out to be asymmetric losses. Let

L( , y) = y, if 6= y and 0 otherwise. We then have the following result.

Corollary 2. Consider the perceptron with weighted loss L. Assume 1 2 without loss of generality. Then the sequence W generated by Algorithm 1 satisfies the weighted mistake bound,

Xn L(W X , y )
 =1



4R2 22

12
2

.

We are not aware of such results for weighted loss. Previous work [8] studies perceptrons

wPitnh=1unLe0v-1e(ntm, yarg).insI,n

and the loss bound there only implies a a technical note, Ratsch and Kivinen [9]

bound on provide a

the unweighted loss: mistake bound of the

4

form

(without

proof):

Pn
 =1

L(W

X

,

y

)



R2 42

,

but

for

the

specific

choice

of

weights

1

=

a2

and 2 = (1 a)2 for any a 2 [0, 1].

Another interesting extension is obtained by allowing the predictions to have a REJECT option. De-

fine LREJ(REJECT, y) = y and LREJ( , y) = L0-1( , y) otherwise. Assume 1 1 2 > 0 with-

out loss of generality. negative classes, and

Choosing the rep(REJECT)

s=tanpd1a2rdPba2si{s1,v2e}crteoprs(in),Rw2 etoobbetarienpP( n)=fo1rLthReEJp(WositXive

and the , y ) 

4R2

2 1

22

(See Appendix C.1).

2

Multiclass Classification. Each instance is assigned exactly one of m classes (i.e.,  = m). Extending binary classification, we choose the standard basis vectors in Rm to be rep( ) for the m classes. The learner predicts score t 2 Rm using the predictor W 2 Rmp. So, ptiroendo(ft)m=argainrgbmecaoxmi teis.: Let wj denote the jth row of W (corresponding to label j). The defini-

hwy, Xi

max
j6=y

hwj

,

X

i

which is identical to recover their bound,

the multiclass margin studied earlier [10]. up to constants2. Moreover, our surrogate

For the multiclass for L0-1:

0-1

loss

L0-1,

we

(t, y) = max 0, 1 + max t
6=y

ty ,

matches the multiclass extension of the Hinge loss studied by [11]. Finally, note that it is straightforward to obtain loss bounds for multiclass perceptron with REJECT option by naturally extending the definitions of rep and LREJ for the binary case.

Ordinal Regression. The goal is to assign ordinal classes (such as ratings) to a set of objects

{X1, X2, . . . } described by their features Xi 2 Rp. In many cases, precise rating information may not be available, but only their relative ranks; i.e., the observations consist of object-rank pairs

(X , y ) where y 2 []. Y is totally-ordered with ">" relation, which in turn induces a partial

ordering on the objects (Xj is preferred to Xj0 if yj > yj0 , Xj and Xj0 are not comparable if

ybjou=ndyPj0 ).n=F1orLt(he

ranking , y ) 

loss (

L( , y) = | y|, the PRank 1)(R2 + 1)/2, where  is a

perceptron algorithm certain rank margin.

[12] enjoys the By a reduction

to multi-class classification with  classes, Algorithm 1 achieves the loss bound 4( 1)2R2/ 2

(albeit, for a different margin ).

Multilabel Classification. This setting generalizes multiclass classification in that instances are

assigned subsets of m classes rather than unique classes, i.e.,  = 2m. The loss function L of

interest may dictate the choice of rep and in turn pred. For example, consider the following subset

losses that treat labels as well as predictions as subsets: (i) Subset 0-1 loss: LIsErr( , y) = 1 if = y or 0 otherwise; (ii) Hamming loss: LHam( , y) = | [ y| | \ y|, and (ii) Error set

size: LErrSetSize( , y) = {(r, s) 2 y  ([m] \ y) : r 62 , s 2 } . A natural choice of rep then

is the rep(

)su=bspe1tmindPicja2torevjectPor ji62n

{+1, 1}d, where d = m = log , ej (where ej's are the standard basis

which can be expressed as vectors in Rm). The learner

predicts score t 2 Rm using a matrix W 2 Rmp. Note that pred(t) = sign(t), where sign is

applied component-wise. The number of predictions is 2m, but we show in Appendix C.2 that the

surrogate (2) and its gradient can be efficiently computed for all of the above losses.

4 Subset Ranking
In subset ranking [13], the task is to learn to rank a number of documents in order of their relevance to a query. We will assume, for simplicity, that the number of documents per query is constant that we denote by m. The input space is a subset of Rmp0 that we can identify with Rp for p = mp0. Each row of an input matrix corresponds to a p0-dimensional feature vector derived jointly using the query
2Perceptron algorithm in [10] is based on a slightly different loss defined as LErrSet(t, y) = 1 if |{r 6= y : tr ty}| > 0 or 0 otherwise (where t = W X). This loss upper bounds L0-1 (because of the way ties are handled, there can be rounds when L0-1 is 0, but LErrSet is 1).

5

and one of the documents associated with it. The predictions are all m! permutations of degree m.

The most natural (but by no means the only one) representation of permutations is to set rep( ) =

/Z where (i) is the position of the document i in the predicted ranking and the normalization

Z ensures that rep( ) is a unit vector. Note that the dimension d of this representation is equal to m.

The minus sign in this representation ensures that pred(t) outputs a permutation that corresponds to

sorting the entries of t in decreasing order, a common convention in existing work. A more general

representation is obtained by setting rep( ) = f real valued function that is applied entry-wise to that k rep( )k2 = 1. To convert an input matrix

(
. X

)T2/hZeRnwpoh(repmrea=lfizma:tpiRo0n)!iZntoR=aipsscaPosretmir=ivc1etflcyt2o(drie)tcer2enasRsuirmnegs,

it seems that we need to learn a matrix W 2 Rmmp0 . However, a natural permutation invariance

requirement (if the documents associated are presented in a permuted fashion, the output scores

should also get permuted in the same way) reduces the dimensionality of W to p0 (see, e.g., [14] for more details). Thus, given a vector w 2 Rp0 we get the score vector as t = Xw. The label space

consists of relevance score vectors y 2 {0, 1, . . . , Ymax}m where Ymax is typically between 1 and 4 (yielding 2 to 5 grades of relevance). Note that the prediction space (of size k = m!) is different

from the label space (of size  = (Ymax + 1)m).

AawhvveearrreyieZptyo(pyou)flliaosrsaschfnuoonirccmetiaoilsnizsNahtDiaoCvneGcbowenehsntiacunhsteiedsndisneufisriunnbegsdeNtaDsraCNnkGDinsCgta.GyFs(obr,omyu)unld=tiegdrabPdyedmi1=.r1eTlleoovg22acy(no1(cin+)eve1j(urit)d)igtm/iZnetn(otysa), loss we define LNDCG = 1 N DCG. Note that any permutation that sorts y in decreasing order gets zero LNDCG. One might worry that the computation of the surrogate defined in (2) and its gradient might require an enumeration of m! permutations. The next lemma allays such a concern.

Lemma 3. When L = LNDCG and rep( ) is chosen as above, the computation of the surrogate (2), as well as its gradient, can be reduced to solving a linear assignment problem and hence can be done in O(m3) time.

We now give a result explaining what it means for a score vector t to have a margin on y when we use a representation of the form described above. Without loss of generality, we may assume that y is sorted in decreasing order of relevance judgements.

LpePmmma Suppoi=se1

4. Suppose rep( ) = f ( )/Z for a strictly decreasing function f : R ! R and Z = f 2(i). Let y be a non-constant relevance judgement vector sorted in decreasing order. i1 < i2, . . . < iN , N 1 are the positions where the relevance drops by a grade or more

(i.e., y(ij) < y(ij 1)). Then t has a margin on y iff t is compatible with y and, for j 2 [N ],

tij 1

tij + f (ij

Z 1) f (ij)

where we define i0 = 1, iN+1 = m + 1 to handle boundary cases.

Note that that case,

if we choose f (i) = the margin condition

i,  > 1 then f (ij 1) above requires less separation

f (ij) = between

dOo(ciujme1n)tsfowr iltahrgdeififje.reInnt

relevance scores down the list (when viewed in decreasing order of relevance scores) than at the top

of the list. We end this section with a loss bound for LNDCG under a margin condition.

Corollary 5. Suppose L = LNDCG and rep( ) is as in Lemma 4. Then, assuming the dataset is linearly separable with margin , the sequence generated by Algorithm 1 with line 9 replaced by

r = X>(pred 1( ) pred 1( y)) 2 Rp01

satisfies

Xn LNDCG(X w , y )



2Ymax +3

* m2 log22(2m) * R2
2

 =1

where kX kop  R.

Note that the result above uses the standard 2-norm based notion of margin. Imagine a subset ranking problem, where only a small number of features are relevant. It is therefore natural to consider a notion of margin where the weight vector that ranks everything perfectly has low group 1 norm, instead of low 2 norm. The 1 margin also appears in the analysis of AdaBoost [2, Definition

6

6.2]. We can use a special case of a more general algorithm given in the appendix (Appendix B.2,

Algorithm 3). Specifically, we replace line 10 with the step w+1 = (r ) 1 (r (w ) r )

where both be

e(awsi)ly=co12mkpwukte2rd.

We set r = log(p0)/(log(p0) (see, e.g., [6, p. 145]).

1). The mapping r and its inverse can

Corollary 6. Suppose L = LNDCG and rep( ) is as in Lemma 4. Then, assuming the dataset is linearly separable with margin by a unit 1 norm w? (kw?k1 = 1), the sequence generated by Algorithm 3 with chosen as above (and line 9 modified as in Corollary 5), satisfies

Xn LNDCG(X w , y )



9 * 2Ymax+3

* m2 log22(2m) * R2
2

* log p0

 =1

where maxj=1,...,po kX,j k2  R and X,j denotes the jth column of X .

5 Multilabel Ranking

As discussed in Section 3, in multilabel classification, both prediction space and label space are {0, 1}m with sizes k =  = 2m. In multilabel ranking, however, the learner has to output rankings as predictions. So, as in the previous section, we have k = m! since the prediction can be any one of m! permutations of the labels. As before, we choose rep( ) = f ( )/Z and hence d = m. However, unlike the previous section, the input is no longer a matrix but a vector X 2 Rp. A prediction t 2 Rd is obtained as W X where W 2 Rmp. Note the contrast with the last section: there, inputs are matrices and a weight vector is learned; here, inputs are vectors and a weight matrix is learned. Since we output rankings, it is reasonable to use a loss that takes positions of labels into account. We can use L = LNDCG. Algorithm 1 now immediately applies. Lemma 3 already showed that is efficiently implementable. We have the following straightforward corollary. Corollary 7. Suppose L = LNDCG and rep( ) is as in Lemma 4. Then, assuming the dataset is linearly separable with margin , the sequence generated by Algorithm 1 satisfies

Xn LNDCG(X w , y )



2Ymax +3

* m2 log22(2m) * R2
2

 =1

where kX k2  R.

The bound above matches the corresponding bound, up to loss specific constants, for the multiclass multilabel perceptron (MMP) algorithm studied by [15]. The definition of margin by [15] for MMP is different from ours since their algorithms are designed specifically for multilabel ranking. Just like them, we can also consider other losses, e.g., precision at top K positions. Another perceptron style algorithm for multilabel ranking adopts a pairwise approach of comparing two labels at a time [16]. However, no loss bounds are derived.

The result above uses the standard Frobenius norm based margin. Imagine a multilabel problem,

where only a small number of features are relevant across all labels. Then, it is natural to consider a

notion of low

oFfrmobaerngiiunswnhoerrme,thwehmeraetrkixWthka2t,1ra=nksPevpje=r1ytkhWinjgkp2e(rWfecjtldyehnaostelsowa

group (2, 1) norm, instead column of W ). We again

use a special case of Algorithm 3 (Appendix B.2). Specifically, we replace line 10 with the step

W +1 the r

= (r ) 1 (r norm of the 2

(W ) norm of

r ) where the columns

(W ) of W .

=W12eksWet

k22,r . r=

Recall that the group log(p)/(log(p) 1).

(2, r)-norm is The mapping

r and its inverse can both be easily computed (see, e.g., [17, Eq. (2)]).

Corollary 8. Suppose L = LNDCG and rep( ) is as in Lemma 4. Then, assuming the dataset is linearly separable with margin by a unit group norm W ? (kW ?k2,1 = 1), the sequence generated by Algorithm 3 with chosen as above, satisfies

Xn LNDCG(X w , y )



9 * 2Ymax+3

* m2 log22(2m) * R2
2

* log p

 =1

where kX k1  R.

7

Loss on Test Points (1-NDCG) Loss on Test Points (1-NDCG)
Loss on Test Points (1-NDCG)

100 Subset Ranking (m=20, p0=30)

10-5 10-10

pred-1((i))=1/i pred-1((i))=-i1.1 pred-1((i))=-i2
20 40 60 80 No. of Training Points (n)
(a)

100

100 Subset Ranking (n=30, p0=30) pred-1((i))=1/i

pred-1((i))=-i1.1

10-5

pred-1((i))=-i2

10-10 15

20 No. of documents in each instance (m)
(b)

25

0.4 L1 vs L2 (s=50, n=50, m=20) Predtron-L2
0.3 Predtron-L1 0.2
0.1
0 500 1000 1500 2000 2500 Data dimensionality (p0)
(c)

Figure 1: Subset Ranking: NDCG loss for different pred 1 choices with varying n (Plot (a)) and m (Plot (b)). As predicted by Lemmas 4 and 5, pred 1( i) = i1.1 is more accurate than 1/i. (c): L1 vs L2 margin. LNDCG for two different Predtron algorithms based on L1 and L2 margin. Data is generated using L1 margin notion but with varying sparsity of the optimal scoring function w.

6 Experiments

We now present simulation results to demonstrate the application of our proposed Predtron framework to subset ranking. We also demonstrate that empirical results match the trend predicted by our error bounds, hence hinting at tightness of our (upper) bounds. Due to lack of space, we focus only on the subset ranking problem. Also, we would like to stress that we do not claim that the basic version of Predtron itself (with  = 1) provides a state-of-the-art ranker. Instead, we wish to demonstrate the applicability and flexibility of our framework in a controlled setting.

We generated n data points X 2 Rmp0 using a Gaussian distribution with independent rows. The

ith row of X represents a document and is sampled from a spherical Gaussian centered at i. We

selected a w 2 Rp0 and also a set of thresholds [1, . . . , m+1] to generate relevance scores; we

set j

=

1 j

,

82



j



m

and 1

=

+1 and m+1

=

1. We set relevance score y (i) of the

ith document in the  th document-set as: y (i) = m j iff j+1  hX (i), wi  j. That is,

y (i) 2 [m 1].

We measure performance of a given method using the NDCG loss LNDCG defined in Section 4. Note that LNDCG is less sensitive to errors in predictions for the less relevant documents in the list. On the other hand, our selection of thresholds i's implies that the gap between scores of lowerranked documents is very small compared to the higher-ranked ones, and hence chances of making mistakes lower down the list is higher.

Figure 1 (a) shows LNDCG (on a test set) for our Predtron algorithm (see Section 4) but with different pred 1 functions. For pred 1( (i)) = f2( ) = i1.1, f2(i 1) f2(i) is monotonically increasing with i. On the other hand, for pred 1( (i)) = f1( ) = 1/i, f1(i 1) f1(i) is monotonically decreasing with i. Lemma 4 shows that the mistake bound (in terms of LNDCG) of Predtron is better when pred 1 function is selected to be f2( (i)) = i1.1 (as well as for f3( (i)) = i2) instead of f1( (i)) = 1/i. Clearly, Figure 1 (a) empirically validates this mistake bound with LNDCG going to almost 0 for f2 and f3 with just 60 training points, while f1 based Predtron has large loss even with n = 100 training points.

Next, we fix the number of training instances to be n = 30 and vary the number of documents m. As the gap between i's decreases for larger i, increasing m implies reducing the margin. Naturally, Predtron with the above mentioned inverse functions has monotonically increasing loss (see Figure 1 (b)). However, f2 and f3 provide zero-loss solutions for larger m when compared to f1.

Finally, we conduct an experiment to show that by selecting appropriate notion of margin, Predtron

can w.

obtain Now,

more accurate Predtron with

solutions. 2-margin

To this end, notion, i.e.,

wsteangdeanredragteraddaietantfrdoemsc[en1t ,h1a]sp0papn0d

select a sparse dependency in

the error bounds while the 1-margin (see Corollary 6) has only s log(p0) dependence. This error

dependency is also revealed by Figure 1 (c), where increasing p0 with fixed s leads to minor increase

in the loss for 1-based Predtron but leads to significantly higher loss for 2-based Predtron.

Acknowledgments A. Tewari acknowledges the support of NSF under grant IIS-1319810.

8

References
[1] Harish G. Ramaswamy and Shivani Agarwal. Classification calibration dimension for general multiclass losses. In Advances in Neural Information Processing Systems, pages 2078-2086, 2012.
[2] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning. MIT press, 2012.
[3] Michael Collins. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pages 1-8, 2002.
[4] Nathan D. Ratliff, J Andrew Bagnell, and Martin Zinkevich. (Approximate) subgradient methods for structured prediction. In International Conference on Artificial Intelligence and Statistics, pages 380- 387, 2007.
[5] Youssef Mroueh, Tomaso Poggio, Lorenzo Rosasco, and Jean-Jeacques Slotine. Multiclass learning with simplex coding. In Advances in Neural Information Processing Systems, pages 2789-2797, 2012.
[6] Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends in Machine Learning, 4(2):107-194, 2011.
[7] Albert B.J. Novikoff. On convergence proofs on perceptrons. In Proceedings of the Symposium on the Mathematical Theory of Automata, volume 12, pages 615-622, 1962.
[8] Yaoyong Li, Hugo Zaragoza, Ralf Herbrich, John Shawe-Taylor, and Jaz S. Kandola. The perceptron algorithm with uneven margins. In Proceedings of the Nineteenth International Conference on Machine Learning, pages 379-386, 2002.
[9] Gunnar Ratsch and Jyrki Kivinen. Extended classification with modified Perceptron, 2002. Presented at the NIPS 2002 Workshop: Beyond Classification and Regression: Learning Rankings, Preferences, Equality Predicates, and Other Structures; abstract available at http://www.cs.cornell.edu/ people/tj/ranklearn/raetsch_kivinen.pdf.
[10] Koby Crammer and Yoram Singer. Ultraconservative online algorithms for multiclass problems. The Journal of Machine Learning Research, 3:951-991, 2003.
[11] Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-based vector machines. The Journal of Machine Learning Research, 2:265-292, 2002.
[12] Koby Crammer and Yoram Singer. Pranking with ranking. Advances in Neural Information Procession Systems, 14:641-647, 2002.
[13] David Cossock and Tong Zhang. Statistical analysis of bayes optimal subset ranking. IEEE Transactions on Information Theory, 54(11):5140-5154, 2008.
[14] Ambuj Tewari and Sougata Chaudhuri. Generalization error bounds for learning to rank: Does the length of document lists matter? In Proceedings of the 32nd International Conference on Machine Learning, volume 37 of JMLR Workshop and Conference Proceedings, 2015.
[15] Koby Crammer and Yoram Singer. A family of additive online algorithms for category ranking. The Journal of Machine Learning Research, 3:1025-1058, 2003.
[16] Eneldo Loza Mencia and Johannes Furnkranz. Pairwise learning of multilabel classifications with perceptrons. In IEEE International Joint Conference on Neural Networks, pages 2899-2906, 2008.
[17] Sham M. Kakade, Shai Shalev-Shwartz, and Ambuj Tewari. Regularization techniques for learning with matrices. Journal of Machine Learning Research, 13:1865-1890, 2012.
9

